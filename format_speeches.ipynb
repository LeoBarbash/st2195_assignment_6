{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17e1fad-dd96-4f02-84a4-ee05140d21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/levbarbash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506e24a-c3bc-4be2-aac7-4bf9cf4752be",
   "metadata": {},
   "source": [
    "1. Load and merge the datasets keeping all information available for the dates in\n",
    "which there is a measurement in “fx.csv”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286ef89d-e772-465e-ae81-bf6ede375863",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.read_csv(\"speeches.csv\", sep='|')\n",
    "speeches = speeches[speeches['date'] >= '1999-01-04']\n",
    "fx = pd.read_csv(\"fx.csv\", sep=',')\n",
    "fx = fx[['TIME_PERIOD', 'OBS_VALUE']]\n",
    "merged = speeches.merge(fx, how='left', left_on='date', right_on='TIME_PERIOD').drop(columns=['TIME_PERIOD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b3f37-b6fa-4633-b1e3-c9d5e54b90ee",
   "metadata": {},
   "source": [
    "3. Handle missing observations for the exchange rate, if any. This should be done\n",
    "replacing any missing exchange rate with the latest information available.\n",
    "Whenever this cannot be done, the relevant entry should be removed entirely\n",
    "from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06a1334-c896-4a87-8f90-68c8ed3b9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['was_null'] = 0\n",
    "merged.loc[merged['OBS_VALUE'].isnull(), 'was_null'] = 1\n",
    "old_dates = merged.loc[merged['was_null'] == 1, 'date']\n",
    "while merged['OBS_VALUE'].isnull().any():\n",
    "    merged.loc[merged['OBS_VALUE'].isnull(), 'date'] = (pd.to_datetime(merged[merged['OBS_VALUE'].isnull()]['date']) \n",
    "                                                        - timedelta(days=1)).astype(str)\n",
    "    merged = merged.drop(columns=['OBS_VALUE'])\n",
    "    merged = merged.merge(fx, how='left', left_on='date', right_on='TIME_PERIOD').drop(columns=['TIME_PERIOD'])\n",
    "merged.loc[merged['was_null'] == 1, 'date'] = old_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fe99c-3f2f-4e58-87c1-86e41ebed84c",
   "metadata": {},
   "source": [
    "4. Calculate the exchange rate return. Extend the original dataset with the\n",
    "following variables: “good_news” (equal to 1 when the exchange rate return is\n",
    "larger than 0.5 percent, 0 otherwise) and “bad_news” (equal to 1 when the\n",
    "exchange rate return is lower than -0.5 percent, 0 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39407e72-0fdb-4e84-a5af-c8a5b0bbe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_val = merged['OBS_VALUE'][1:].reset_index(drop=True)\n",
    "merged['prev_OBS_VALUE'] = prev_val\n",
    "merged.loc[merged['prev_OBS_VALUE'].isnull(), 'prev_OBS_VALUE'] = fx[fx['TIME_PERIOD'] == '1999-01-13']['OBS_VALUE'].reset_index(drop=True)[0]\n",
    "merged['return'] = (merged['OBS_VALUE'] - merged['prev_OBS_VALUE']) / (merged['prev_OBS_VALUE'] / 100)\n",
    "merged['good_news'] = 0\n",
    "merged['bad_news'] = 0\n",
    "merged.loc[merged['return'] >= 0.5, 'good_news'] = 1\n",
    "merged.loc[merged['return'] <= -0.5, 'bad_news'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41409f3-5331-4874-890a-4992c7ff5c8f",
   "metadata": {},
   "source": [
    "5. Remove the entries for which contents column has NA values. Generate and\n",
    "store in csv the following tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069a155-0f09-419d-93ea-80279e1a0f0f",
   "metadata": {},
   "source": [
    "a. “good_indicators” – with the 20 most common words (excluding articles,\n",
    "prepositions and similar connectors) associated with entries wherein\n",
    "“good_news” is equal to 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05838368-3bd6-4696-83b5-46ae7148162f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/levbarbash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>euro</td>\n",
       "      <td>8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>financial</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>monetary</td>\n",
       "      <td>6641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>policy</td>\n",
       "      <td>6067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>area</td>\n",
       "      <td>4317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>economic</td>\n",
       "      <td>4267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>central</td>\n",
       "      <td>4261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>european</td>\n",
       "      <td>3701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>market</td>\n",
       "      <td>3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>would</td>\n",
       "      <td>3336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>price</td>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>inflation</td>\n",
       "      <td>3039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>banks</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ecb</td>\n",
       "      <td>2906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>bank</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>stability</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>growth</td>\n",
       "      <td>2373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>die</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>countries</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>new</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count\n",
       "14       euro   8185\n",
       "15  financial   7659\n",
       "20   monetary   6641\n",
       "21     policy   6067\n",
       "32       area   4317\n",
       "33   economic   4267\n",
       "34    central   4261\n",
       "39   european   3701\n",
       "40     market   3665\n",
       "41      would   3336\n",
       "43      price   3116\n",
       "46  inflation   3039\n",
       "48      banks   2946\n",
       "49        ecb   2906\n",
       "54       bank   2743\n",
       "57  stability   2501\n",
       "58     growth   2373\n",
       "62        die   2190\n",
       "68  countries   1982\n",
       "69        new   1977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "merged = merged.dropna(subset=['contents'])\n",
    "merged['contents'] = merged['contents'].str.lower()\n",
    "good_inds = Counter(\" \".join(merged[merged['good_news'] == 1][\"contents\"]).split()).most_common()\n",
    "good_inds_df = pd.DataFrame(good_inds, columns=['word', 'count'])\n",
    "stop_words = pd.Series(list(set(stopwords.words('english'))))\n",
    "stop_words = pd.concat([stop_words, pd.Series(['de', '–', 'la', 'also', 'der', 'may'])], ignore_index=True)\n",
    "stop_words_df = pd.DataFrame(stop_words, columns=['word'])\n",
    "stop_words_df['is_stop_word'] = 1\n",
    "merged_good_inds = good_inds_df.merge(stop_words_df, how='left', left_on='word', right_on='word')\n",
    "merged_good_inds[merged_good_inds['is_stop_word'] != 1].drop(columns=['is_stop_word']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce7c47-c781-4e77-b348-86d2d7424b6c",
   "metadata": {},
   "source": [
    "b. “bad_indicators” – with the 20 most common words (excluding articles,\n",
    "prepositions and similar connectors) associated with entries wherein\n",
    "“bad_news” is equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139fe469-140c-4f1d-b854-fb80ab12100c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>euro</td>\n",
       "      <td>8733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>financial</td>\n",
       "      <td>7842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>monetary</td>\n",
       "      <td>7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>policy</td>\n",
       "      <td>6158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>area</td>\n",
       "      <td>4969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>economic</td>\n",
       "      <td>4795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>central</td>\n",
       "      <td>4389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>european</td>\n",
       "      <td>4198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>market</td>\n",
       "      <td>3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>would</td>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>banks</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>price</td>\n",
       "      <td>3188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ecb</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>inflation</td>\n",
       "      <td>2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>bank</td>\n",
       "      <td>2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>growth</td>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>stability</td>\n",
       "      <td>2625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>banking</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>new</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>countries</td>\n",
       "      <td>2198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count\n",
       "14       euro   8733\n",
       "18  financial   7842\n",
       "20   monetary   7140\n",
       "23     policy   6158\n",
       "31       area   4969\n",
       "32   economic   4795\n",
       "34    central   4389\n",
       "36   european   4198\n",
       "39     market   3890\n",
       "40      would   3809\n",
       "46      banks   3439\n",
       "51      price   3188\n",
       "52        ecb   3027\n",
       "53  inflation   2927\n",
       "54       bank   2844\n",
       "56     growth   2720\n",
       "58  stability   2625\n",
       "65    banking   2344\n",
       "66        new   2273\n",
       "69  countries   2198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_inds = Counter(\" \".join(merged[merged['bad_news'] == 1][\"contents\"]).split()).most_common()\n",
    "bad_inds_df = pd.DataFrame(bad_inds, columns=['word', 'count'])\n",
    "merged_bad_inds = bad_inds_df.merge(stop_words_df, how='left', left_on='word', right_on='word')\n",
    "merged_bad_inds[merged_bad_inds['is_stop_word'] != 1].drop(columns=['is_stop_word']).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
